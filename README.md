**1-bit LLMs**

- [Fine-tuning LLMs to 1.58bit: extreme quantization made easy](https://huggingface.co/blog/1_58_llm_extreme_quantization)
- [Hugging Face 1Bit LLMs Community](https://huggingface.co/HF1BitLLM)
- [Hugging Face 1bitLLM](https://huggingface.co/1bitLLM)
- [bitnet.cpp from Microsoft: Run LLMs locally on CPU! (hands-on)](https://www.youtube.com/watch?v=C4OYJAs4O60)
- [microsoft/BitNet](https://github.com/microsoft/BitNet)
- [microsoft/T-MAC](https://github.com/microsoft/T-MAC)

**Arvind Neelakantan**

- [Arvind Neelakantan - Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space](https://www.youtube.com/watch?v=EeBj4TyW8B8)
- [Arvind Neelakantan - Introduction to Text and Code Embeddings in the OpenAI API](https://www.youtube.com/watch?v=mnTV_TIkf9M)
- [Arvind Neelakantan - Knowledge Representation And Reasoning With Deep Neural Networks](https://www.youtube.com/watch?v=lc68_d_DnYs)
- [Arvind Neelakantan - Text and Code Embeddings](https://www.youtube.com/watch?v=xlm5Rb0EGWs)

**Brazil**

- [Acordo Ortográfico da Língua Portuguesa](https://academia.org.br/sites/default/files/conteudo/o_acordo_ortogr_fico_da_lngua_portuguesa_anexoi_e_ii.pdf)
- [Aprendizado em Redes Neurais Profundas (UFV)](https://ufv-inf721.lucasnferreira.com/)
- [BotBot](https://www.botbot.bot/)
- [Brasileiras em PLN](https://brasileiraspln.com/)
- [Cabrita](https://github.com/22-hours/cabrita)
- [Curso Deep Learning em Python (PUC Rio)](https://ica.ele.puc-rio.br/cursos/deep-learning-em-python/)
- [Deep Learning (UFG)](https://www.youtube.com/playlist?list=PLSZEVLiOtIgF19_cPrvhJC2bWn-dUh1zB)
- [IA para o Bem de Todos](https://www.gov.br/mcti/pt-br/acompanhe-o-mcti/cct/legislacao/arquivos/IA_para_o_Bem_de_Todos.pdf)
- [Maritaca AI](https://www.maritaca.ai/)
- [Open Portuguese LLM Leaderboard](https://huggingface.co/spaces/eduagarcia/open_pt_llm_leaderboard)
- [Regras para divisão silábica](https://michaelis.uol.com.br/moderno-portugues/nocoes-gramaticais/regras-para-divisao-silabica/)
- [Sabiá-2: A New Generation of Portuguese Large Language Models](https://arxiv.org/pdf/2403.09887)
- [maritaca-ai/sabia-7b](https://huggingface.co/maritaca-ai/sabia-7b)

**Book club**

- [Build a Large Language Model](https://www.youtube.com/playlist?list=PLheFoa5iXad7-YWe-Wd7n_1udggti4JiT)
- [Deep Learning Book by Ian Goodfellow](https://www.youtube.com/playlist?list=PLbBjZEwyU7W1CDs3Vx_GOJ9b3EgYQB3GE)
- [Dive into Deep Learning](https://www.youtube.com/playlist?list=PLGSHbNsNO4ViFXawDmx-kEz7zGziOpNSb)
- [Hands-On Machine Learning with Scikit-Learn & TensorFlow](https://www.youtube.com/playlist?list=PLheFoa5iXad7r2AhM3mwGr3t_GUGumQC2)

**Courses**

- [Andrej Karpathy - CS231n Winter 2016](https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC)
- [Andrej Karpathy - Neural Networks: Zero to Hero](https://karpathy.ai/zero-to-hero.html)
- [Geoffrey Hinton - Neural Networks for Machine Learning](https://www.youtube.com/playlist?list=PLLssT5z_DsK_gyrQ_biidwvPYCRNGI3iv)
- [Machine Learning Crash Course (Google for Developers)](https://developers.google.com/machine-learning/crash-course)

**Dark Knowledge**

- ["Knowledge Distillation" Explanation and Implementation](https://www.youtube.com/watch?v=9guKFI_yVNc)
- [Geoffrey Hinton - Dark Knowledge (slides)](https://www.ttic.edu/dl/dark14.pdf)
- [Geoffrey Hinton - Dark Knowledge (video)](https://www.youtube.com/watch?v=F5gXXubLo9s)
- [Geoffrey Hinton - Distilling the Knowledge in a Neural Network (2015)](https://arxiv.org/pdf/1503.02531)
- [Kullback–Leibler divergence (distance between two probability distributions)](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)

**Datasets**

- [BlogSet-BR (Blogspot)](https://www.inf.pucrs.br/linatural/wordpress/recursos-e-ferramentas/blogset-br/)
- [Common Crawl (250 billion pages)](https://commoncrawl.org/latest-crawl)
- [DBpedia (Wikipedia)](https://databus.dbpedia.org/dbpedia/collections/latest-core)
- [Form Understanding in Noisy Scanned Documents (FUNSD)](https://guillaumejaume.github.io/FUNSD/)
- [Ngram (Wikipedia)](https://nlp.cs.nyu.edu/wikipedia-data/)
- [The Pile (800GB of diverse text)](https://pile.eleuther.ai/)
- [TinyStories (synthetic short stories)](https://huggingface.co/datasets/roneneldan/TinyStories)

**Debugging**

- [Andrej Karpathy - A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)
- [CS 230 -  Deep Learning Tips and Tricks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks)
- [OpenAI - Techniques for training large neural networks](https://openai.com/index/techniques-for-training-large-neural-networks)
- [StackOverflow - Neural network always predict the same class](https://stackoverflow.com/a/41493375)
- [Yann LeCun - Efficient BackProp](https://cseweb.ucsd.edu/classes/wi08/cse253/Handouts/lecun-98b.pdf)
- [Yoshua Bengio - Practical Recommendations for Gradient-Based Training of Deep Architetures](https://arxiv.org/pdf/1206.5533)

**Dimensionality reduction (PCA, LSA, t-SNE, UMAP, ...)**

- [CannyLab/tsne-cuda](https://github.com/CannyLab/tsne-cuda)
- [Distill - How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)
- [Laurens van der Maaten - Visualizing Data Using t-SNE](https://www.youtube.com/watch?v=RJVL80Gg3lA)
- [Simon Carbonnoelle - Visualizing Data using t-SNE](https://sites.uclouvain.be/ispgroup/uploads/ISPS/slides_120516.pdf)
- [sklearn.manifold.TSNE](https://scikit-learn.org/dev/modules/generated/sklearn.manifold.TSNE.html)

**Discovering sentiment**

- [Alec Radford, Rafal Jozefowicz, Ilya Sutskever - Learning to Generate Reviews and Discovering Sentiment (2017)](https://arxiv.org/abs/1704.01444)
- [Andrej Karpathy, Justin Johnson, Li Fei-Fei - Visualizing and Understanding Recurrent Networks (2015)](https://arxiv.org/abs/1506.02078)
- [The unreasonable effectiveness of one neuron](https://rakeshchada.github.io/Sentiment-Neuron.html)
- [Unsupervised sentiment neuron](https://openai.com/index/unsupervised-sentiment-neuron/)
- [openai/generating-reviews-discovering-sentiment](https://github.com/openai/generating-reviews-discovering-sentiment)
- [rakeshchada/generating-reviews-discovering-sentiment](https://github.com/rakeshchada/generating-reviews-discovering-sentiment/blob/95a1933/Sentiment-Neuron-Yelp.ipynb)

**Dying ReLU**

- [How to check for dead relu neurons](https://datascience.stackexchange.com/questions/18810/how-to-check-for-dead-relu-neurons)
- [What is the "dying ReLU" problem in neural networks?](https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks)

**Hardware**

- [What Is Resizable BAR on a GPU, and Should You Use It?](https://www.howtogeek.com/819578/what-is-resizable-bar-on-a-gpu/)
- [What is XMP or DOCP and how to enable it?](https://www.nicehash.com/blog/post/what-is-xmp-or-docp-and-how-to-enable-it)

**Inference libraries**

- [InternLM/lmdeploy](https://github.com/InternLM/lmdeploy)
- [OpenNMT/CTranslate2](https://github.com/OpenNMT/CTranslate2)
- [inferflow/inferflow](https://github.com/inferflow/inferflow)
- [turboderp/exllamav2](https://github.com/turboderp/exllamav2)

**Jobs**

- [aijobs.ai](https://aijobs.ai/)
- [aijobs.net](https://aijobs.net/)
- [deep learning on arc.dev](https://arc.dev/remote-jobs/deep-learning)

**LLM training**

- [Sebastian Raschka -  Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)
- [Thom Wolf - A little guide to building Large Language Models in 2024](https://www.youtube.com/watch?v=2-SPH9hIKT8)

**Math**

- [Interactive Linear Algebra](https://textbooks.math.gatech.edu/ila/)

**Miscellanea**

- [AMA Geoffrey Hinton](https://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/)
- [Alan Turing, Cybernetics and the Secrets of Life](https://www.youtube.com/watch?v=rPLvj-GcfSU)
- [Calculating the Number of flops for a given Neural Network?](https://stackoverflow.com/q/55831235)
- [ChatGPT: 30 Year History | How AI Learned to Talk](https://www.youtube.com/watch?v=OFS90-FX6pg)
- [Eliezer Yudkowsky - AGI Ruin: A List of Lethalities](https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities)
- [Jürgen Schmidhuber - Who Invented Backpropagation?](https://people.idsia.ch/~juergen/who-invented-backpropagation.html)
- [Leo Gao - The Decade of Deep Learning](https://bmk.sh/2019/12/31/The-Decade-of-Deep-Learning/)
- [Michael Castelle - Deep Learning as an Epistemic Ensemble](https://castelle.org/pages/deep-learning-as-an-epistemic-ensemble.html)
- [Why did Marvin Minsky claim the multilayer perceptron wasn’t likely going to work?](https://www.quora.com/Why-did-Marvin-Minsky-claim-the-multilayer-perceptron-wasn-t-likely-going-to-work-without-giving-much-evidence-Is-isn-t-intuitvely-obvious-that-multilayer-perceptron-could-overcome-the-limitations-of-single-layer)
- [calflops: a FLOPs and Params calculate tool for neural networks](https://github.com/MrYxJ/calculate-flops.pytorch)

**OpenAI GPT1**

- [Alec Radford - Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
- [GPT1 paper annotated](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf)
- [openai-community/openai-gpt (Hugging Face)](https://huggingface.co/openai-community/openai-gpt)
- [openai/finetune-transformer-lm (GitHub)](https://github.com/openai/finetune-transformer-lm)

**Prompt engineering**

- [The Prompt Report: A Systematic Survey of Prompting Techniques (2024)](https://arxiv.org/abs/2406.06608)

**Python**

- [Common Gotchas](https://docs.python-guide.org/writing/gotchas/)
- [Dead Simple Python](https://www.google.com/books/edition/Dead_Simple_Python/MPBmEAAAQBAJ)
- [Fluent Python](https://www.google.com/books/edition/Fluent_Python/bIZHCgAAQBAJ)
- [LMQL (programming language for LLMs)](https://github.com/eth-sri/lmql)
- [PyOxidizer (executable with embedded Python)](https://github.com/indygreg/PyOxidizer)
- [Wait, IPython Can Do That?!](https://switowski.com/blog/wait-ipython-can-do-that/)
- [objexplore (CLI object inspecting)](https://github.com/kylepollina/objexplore)
- [pudb (nicer CLI debugger)](https://github.com/inducer/pudb)

**Quantization**

- [Maarten Grootendorst - A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)

**Recurrent neural networks**

- [Christopher Olah - Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [Ilya Sutskever, James Martens, Geoffrey Hinton - Generating Text with Recurrent Neural Networks (2011)](https://icml.cc/2011/papers/524_icmlpaper.pdf)
- [Machine Learning Spotlight I: Investigating Recurrent Neural Networks](https://medium.com/@SAPCAI/machine-learning-spotlight-i-investigating-recurrent-neural-networks-40a84067e916)
- [Were RNNs All We Needed? (2024)](https://arxiv.org/pdf/2410.01201)
- [XLSTM - Extended LSTMs with sLSTM and mLSTM (paper explained)](https://www.youtube.com/watch?v=0aWGTNS03PU)

**Reinforcement Learning from Human Feedback (RLHF)**

- [Training language models to follow instructions with human feedback](https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf)
- [WebGPT: Browser-assisted question-answering with human feedback](https://arxiv.org/pdf/2112.09332)

**Retrieval-Augmented Generation (RAG)**

- [DataLine](https://github.com/RamiAwar/dataline)
- [Verba](https://github.com/weaviate/Verba)
- [anything-llm/collector/processSingleFile/convert/](https://github.com/Mintplex-Labs/anything-llm/tree/9b86bbd/collector/processSingleFile/convert)

**Source code analysis**

- [Building a better repository map with tree sitter](https://aider.chat/2023/10/22/repomap.html)
- [codeqai](https://github.com/fynnfluegge/codeqai)

**Snippets**

- [def seed\_everything](https://github.com/ai-forever/ru-dalle/blob/e96631a/rudalle/utils.py#L10-L17)

**Structured output**

- [llama.cpp formal grammar](https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md)
- [outlines-dev/outlines](https://github.com/outlines-dev/outlines)

**Talks**

- [Alec Radford - Learning From Text (2020)](https://www.youtube.com/watch?v=BnpB3GrpsfM)
- [Andrew Ng - GPU Technology Conference Keynote (2015)](https://video.ibm.com/recorded/60113824)
- [David Rumelhart - Brainstyle Computation and Learning (1987)](http://thesciencenetwork.org/programs/cogsci-2010/david-rumelhart)
- [David Rumelhart - Connectionist Learning (1990)](http://thesciencenetwork.org/programs/cogsci-2010/david-rumelhart-1)
- [Fei-Fei Li on Uncommon Knowledge](https://www.youtube.com/watch?v=10_fZRdCM7Q)
- [Geoffrey Hinton - Q&A (AI subjective experience at 16:30, AI rights at 19:40)](https://www.youtube.com/watch?v=PTF5Up1hMhw)
- [Ilya Sutskever - GPT-2](https://www.youtube.com/watch?v=T0I88NhR_9M)
- [Ilya Sutskever - Sequence to Sequence Learning with Neural Networks](https://www.youtube.com/watch?v=-uyXE7dY5H0)
- [Jack Rae - Techniques to Make Language Models More Useful](https://www.youtube.com/watch?v=8krnBzywtbs)
- [Richard Socher - Deep Learning for Natural Language Processing](https://www.youtube.com/watch?v=oGk1v1jQITw)
- [Richard Socher - Recurrent Neural Networks and Language Models](https://www.youtube.com/watch?v=Keqep_PKrY8)
- [Tomáš Mikolov - Deep Learning in NLP and Beyond](https://www.youtube.com/watch?v=zAJdS-nBdL0)
- [Yoshua Bengio - Recurrent Neural Networks](https://www.youtube.com/watch?v=AYku9C9XoB8)

**Text prediction**

- [Andrej Karpathy - Recurrent Neural Networks & Long Short-Term Memory](https://www.youtube.com/watch?v=qPcCk1V1JO8)
- [Andrej Karpathy - The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
- [Andrej Karpathy - min-char-rnn.py](https://gist.github.com/karpathy/d4dee566867f8291f086)
- [François Chollet - Character-level text generation with LSTM](https://keras.io/examples/generative/lstm_character_level_text_generation/)
- [Generating Names with a Character-Level RNN (PyTorch tutorial)](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)
- [Kyubyong/word\_prediction (CNN)](https://github.com/Kyubyong/word_prediction)
- [nikhilbarhate99/Char-RNN-PyTorch](https://github.com/nikhilbarhate99/Char-RNN-PyTorch)

**Transformers**

- [GTC 2024 features the authors of "Attention Is All You Need"](https://www.youtube.com/watch?v=hC_qASRcBhU)
- [Paper walkthrough (video)](https://www.youtube.com/watch?v=iDulhoQ2pro)
- [Papers We Love - Attention Is All You Need (video)](https://www.youtube.com/watch?v=TvU3ayIMWpE)
- [Positional Encoding in Transformer (reddit)](https://www.reddit.com/r/MachineLearning/comments/cttefo/comment/exs7d08/)
- [Transformer Explainer](https://poloclub.github.io/transformer-explainer/)
- [Visual Guide to Transformer Neural Networks (video)](https://www.youtube.com/watch?v=dichIcUZfOw)
- [What if we drop the causal mask in auto-regressive Transformer? (Stack Exchange)](https://ai.stackexchange.com/q/40917/87091)
- [Why are embeddings added, not concatenated? (Stack Exchange)](https://ai.stackexchange.com/q/35990/87091)

**Tokenization**

- [BPE pseudocode](http://www.pennelynn.com/Documents/CUJ/HTML/94HTML/19940045.HTM#0045_0026)
- [BPE video demo](https://www.youtube.com/watch?v=HEikzVL-lZU)
- [Karpathy BPE implementation](https://github.com/karpathy/minbpe)
- [OpenAI BPE implementation](https://github.com/openai/tiktoken)
- [OpenAI online tokenizer](https://platform.openai.com/tokenizer)
- [Sam Gbafa - Words to Bytes: Exploring Language Tokenizations](https://www.youtube.com/watch?v=TsFLqbiim4M)

**Tomas Mikolov**

- [Chris McCormick - word2vec\_commented](https://github.com/chrisjmccormick)
- [Hendrik Heuer - word2vec from theory to practice](http://hen-drik.de/pub/Heuer%20-%20word2vec%20-%20From%20theory%20to%20practice.pdf)
- [Jake Tae - Word2vec from Scratch](https://jaketae.github.io/study/word2vec/)
- [JosephSBoyle/skip\_gram](https://github.com/JosephSBoyle/skip_gram)
- [Joshua T. Goodman - A Bit of Progress in Language Modeling (2008)](https://arxiv.org/pdf/cs/0108005)
- [Tomas Mikolov - Natural Language Processing Lecture (2020)](https://www.youtube.com/watch?v=tX_D97Vf08k)
- [Tomas Mikolov - Statistical Language Models Based on Neural Networks (2012, slides)](http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf)
- [Tomas Mikolov - Statistical Language Models Based on Neural Networks (2012, thesis)](https://www.fit.vut.cz/study/phd-thesis-file/283/283.pdf)
- [Tomas Mikolov - Subword Language Modeling with Neural Networks](http://www.fit.vutbr.cz/~imikolov/rnnlm/char.pdf)
- [Tomas Mikolov - Test of Time Award at NeurIPS (Facebook post)](https://news.ycombinator.com/item?id=38654038)
- [Word2Vec Research Paper Explained](https://towardsdatascience.com/word2vec-research-paper-explained-205cb7eecc30)
- [tmikolov/word2vec](https://github.com/tmikolov/word2vec)

**Tools**

- [marimo (git-friendly notebook)](https://marimo.io/)

**Vector databases**

- [Chroma](https://www.trychroma.com/)
- [sqlite-vec](https://github.com/asg017/sqlite-vec)

**Visualization**

- [Deep Dream I](https://www.youtube.com/watch?v=BsYjsgE76hc)
- [Deep Dream II](https://www.youtube.com/watch?v=5biMPQOcEy8)
- [Deep Dream III](https://www.youtube.com/watch?v=srn3tMW9Ges)
- [Distill](https://distill.pub/)
- [Geoffrey Hinton - Neural Networks for Machine Learning (MNIST)](https://www.youtube.com/watch?v=uixGgMInc48)
- [Lukasz Kaiser - Neural GPU Learned Algorithms](https://www.youtube.com/watch?v=LzC8NkTZAF4)
- [OpenAI Microscope](https://microscope.openai.com/)
- [TensorFlow Playground](http://playground.tensorflow.org/)
- [Visualization of a fully connected neural network (MNIST)](https://www.youtube.com/watch?v=sDDjJRnnHao)
- [Yann LeCun - Convolutional Network Demo from 1989 (MNIST)](https://www.youtube.com/watch?v=FwFduRA_L6Q)
